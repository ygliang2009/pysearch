[spider]
#爬虫爬行深度
deep = 2
#爬取超时时间
timeout = 5
#爬取重试次数
retry = 3
#爬虫日志路径设置
slogpath = log
slogfile = spider.log
sloglevel = debug

#database configure 
[database]
#数据库配置
user = root
password = public

#rank policy 
[rank]
titleweight = 10
#频率排序算法 -- 按照单词出现在文档的频率进行排序
frequence = 10
distance = 10
position = 10

#服务器通信
[server]
address = localhost
port = 9898
#监听队列长度
listennum = 256
#超时时间，以秒为计算单位
timeout = 3
#server进程信息
pidpath = var
pidfile = se.pid
#接收限制,recvfrom()参数的限制大小
recvlen = 1024
#接收缓存大小
recvbuf = 1024
#发送缓存大小
sendbuf = 10240

[build]
#描述信息返回的长度
block = 32

#back up
#备份文件目录，不配值则做系统默认(Builder.py)
[backinfo]
#backpath= /home/chemical/workspace/python/se/backup/
backpath= /home/chemical/workspace/python/se/backup
#文件的备份格式
rawtext = .file
rawhtml = .htm
#备份压缩格式
backtext = .file.zip
backhtml = .htm.zip

#log configure
[log]
#日志路径
logpath = log/
#日志文件名
logfile = se.log
#日志级别
loglevel = debug
